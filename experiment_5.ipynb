{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWaNIQfpXhNI",
        "outputId": "0d9db942-d36e-464c-cbbf-8b45c6032cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from NLTk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from NLTk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from NLTk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from NLTk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install NLTk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru1c_IRlXl9N",
        "outputId": "5b147645-58c0-44ce-b6bc-7f72c574a09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize , word_tokenize"
      ],
      "metadata": {
        "id": "0pYG-bNQXqDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"Tokenization refers to converting sensitive or complex data into smaller, manageable, or non-sensitive units depending on the context. It is widely used in data security to protect sensitive information and in Natural Language Processing (NLP) to segment text for analysis.In data security, tokenization replaces sensitive values (e.g., credit card numbers, SSNs) with tokens that have no exploitable meaning without access to a secure token vault. This vault stores the mapping between tokens and original data, often encrypted and access-controlled. Tokens can be irreversible (for anonymization) or reversible (for operational needs like refunds). They may also be format-preserving to maintain compatibility with existing systems.\"\n",
        "output = sent_tokenize(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQXQM2vIXt5e",
        "outputId": "849de978-9bf6-4d99-8ddf-6fe70160c169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization refers to converting sensitive or complex data into smaller, manageable, or non-sensitive units depending on the context.', 'It is widely used in data security to protect sensitive information and in Natural Language Processing (NLP) to segment text for analysis.In data security, tokenization replaces sensitive values (e.g., credit card numbers, SSNs) with tokens that have no exploitable meaning without access to a secure token vault.', 'This vault stores the mapping between tokens and original data, often encrypted and access-controlled.', 'Tokens can be irreversible (for anonymization) or reversible (for operational needs like refunds).', 'They may also be format-preserving to maintain compatibility with existing systems.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "pAIpIZSsZfJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(output)):\n",
        "  words=nltk.word_tokenize(output[i])\n",
        "  words=[stemmer.stem(word) for word in words]\n",
        "  output[i]=' '.join(words)"
      ],
      "metadata": {
        "id": "OaZY_2e4bRBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ9UVFzDc-Nz",
        "outputId": "755ea412-ba3d-4dbe-b6ed-ab2e176ef716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenrefertoconvertsensitorcomplexdataintosmal , manag , ornon-sensitunitdependonthecontext .',\n",
              " 'itiswideuseindatasecurtoprotectsensitinformandinnaturlanguagprocess ( nlp ) tosegmenttextforanalysis.indatasecur , tokenreplacsensitvalu ( e.g . , creditcardnumb , ssn ) withtokenthathavenoexploitmeanwithoutaccesstoasecurtokenvault .',\n",
              " 'thivaultstorethemapbetweentokenandorigindata , oftenencryptandaccess-control .',\n",
              " 'tokencanbeirrev ( foranonym ) orrev ( foroperneedlikerefund ) .',\n",
              " 'theymayalsobeformat-preservtomaintaincompatwithexistsystem .']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "OYFbUZDYdZ0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "O9lgzpkJdb5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(output)):\n",
        "    words = word_tokenize(output[i])\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    output[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "Lu0ewdAfdftL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rOhc0cPdvph",
        "outputId": "400912fb-a5d2-46fd-f86c-657595d541ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenrefertoconvertsensitorcomplexdataintosmaller , manag , ornon-sensitunitdependonthecontext .',\n",
              " 'itiswideuseindatasecurtoprotectsensitinformandinnaturlanguagprocess ( nlp ) tosegmenttextforanalysis.indatasecur , tokenreplacsensitvalu ( e.g. , creditcardnumber , ssn ) withtokenthathavenoexploitmeanwithoutaccesstoasecurtokenvault .',\n",
              " 'thivaultstorethemapbetweentokenandorigindata , oftenencryptandaccess-control .',\n",
              " 'tokencanbeirrevers ( foranonym ) orrevers ( foroperneedlikerefund ) .',\n",
              " 'theymayalsobeformat-preservtomaintaincompatwithexistsystem .']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = nltk.word_tokenize(input)\n",
        "tag_word = nltk.pos_tag(word)\n",
        "print(tag_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkxgCpY1g5Yg",
        "outputId": "33c0041c-a1b9-48a3-9a26-d2b135438616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Tokenization', 'NN'), ('refers', 'NNS'), ('to', 'TO'), ('converting', 'VBG'), ('sensitive', 'JJ'), ('or', 'CC'), ('complex', 'JJ'), ('data', 'NNS'), ('into', 'IN'), ('smaller', 'JJR'), (',', ','), ('manageable', 'JJ'), (',', ','), ('or', 'CC'), ('non-sensitive', 'JJ'), ('units', 'NNS'), ('depending', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('context', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('widely', 'RB'), ('used', 'VBN'), ('in', 'IN'), ('data', 'NNS'), ('security', 'NN'), ('to', 'TO'), ('protect', 'VB'), ('sensitive', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('in', 'IN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('to', 'TO'), ('segment', 'NN'), ('text', 'NN'), ('for', 'IN'), ('analysis.In', 'JJ'), ('data', 'NNS'), ('security', 'NN'), (',', ','), ('tokenization', 'NN'), ('replaces', 'NNS'), ('sensitive', 'JJ'), ('values', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('credit', 'NN'), ('card', 'NN'), ('numbers', 'NNS'), (',', ','), ('SSNs', 'NNP'), (')', ')'), ('with', 'IN'), ('tokens', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('no', 'DT'), ('exploitable', 'JJ'), ('meaning', 'NN'), ('without', 'IN'), ('access', 'NN'), ('to', 'TO'), ('a', 'DT'), ('secure', 'NN'), ('token', 'VBN'), ('vault', 'NN'), ('.', '.'), ('This', 'DT'), ('vault', 'NN'), ('stores', 'NNS'), ('the', 'DT'), ('mapping', 'NN'), ('between', 'IN'), ('tokens', 'NNS'), ('and', 'CC'), ('original', 'JJ'), ('data', 'NNS'), (',', ','), ('often', 'RB'), ('encrypted', 'VBN'), ('and', 'CC'), ('access-controlled', 'JJ'), ('.', '.'), ('Tokens', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('irreversible', 'JJ'), ('(', '('), ('for', 'IN'), ('anonymization', 'NN'), (')', ')'), ('or', 'CC'), ('reversible', 'JJ'), ('(', '('), ('for', 'IN'), ('operational', 'JJ'), ('needs', 'NNS'), ('like', 'IN'), ('refunds', 'NNS'), (')', ')'), ('.', '.'), ('They', 'PRP'), ('may', 'MD'), ('also', 'RB'), ('be', 'VB'), ('format-preserving', 'JJ'), ('to', 'TO'), ('maintain', 'VB'), ('compatibility', 'NN'), ('with', 'IN'), ('existing', 'VBG'), ('systems', 'NNS'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "named_Ent = nltk.ne_chunk(tag_word)\n",
        "named_Ent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "pUZ7XjqCjQFJ",
        "outputId": "727a8dc3-e20b-4039-d6fc-77741136d357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'svgling'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tree/tree.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0msvgling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('GPE', [('Tokenization', 'NN')]), ('refers', 'NNS'), ('to', 'TO'), ('converting', 'VBG'), ('sensitive', 'JJ'), ('or', 'CC'), ('complex', 'JJ'), ('data', 'NNS'), ('into', 'IN'), ('smaller', 'JJR'), (',', ','), ('manageable', 'JJ'), (',', ','), ('or', 'CC'), ('non-sensitive', 'JJ'), ('units', 'NNS'), ('depending', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('context', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('widely', 'RB'), ('used', 'VBN'), ('in', 'IN'), ('data', 'NNS'), ('security', 'NN'), ('to', 'TO'), ('protect', 'VB'), ('sensitive', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('in', 'IN'), Tree('ORGANIZATION', [('Natural', 'NNP'), ('Language', 'NNP')]), ('Processing', 'NNP'), ('(', '('), Tree('ORGANIZATION', [('NLP', 'NNP')]), (')', ')'), ('to', 'TO'), ('segment', 'NN'), ('text', 'NN'), ('for', 'IN'), ('analysis.In', 'JJ'), ('data', 'NNS'), ('security', 'NN'), (',', ','), ('tokenization', 'NN'), ('replaces', 'NNS'), ('sensitive', 'JJ'), ('values', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('credit', 'NN'), ('card', 'NN'), ('numbers', 'NNS'), (',', ','), Tree('ORGANIZATION', [('SSNs', 'NNP')]), (')', ')'), ('with', 'IN'), ('tokens', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('no', 'DT'), ('exploitable', 'JJ'), ('meaning', 'NN'), ('without', 'IN'), ('access', 'NN'), ('to', 'TO'), ('a', 'DT'), ('secure', 'NN'), ('token', 'VBN'), ('vault', 'NN'), ('.', '.'), ('This', 'DT'), ('vault', 'NN'), ('stores', 'NNS'), ('the', 'DT'), ('mapping', 'NN'), ('between', 'IN'), ('tokens', 'NNS'), ('and', 'CC'), ('original', 'JJ'), ('data', 'NNS'), (',', ','), ('often', 'RB'), ('encrypted', 'VBN'), ('and', 'CC'), ('access-controlled', 'JJ'), ('.', '.'), ('Tokens', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('irreversible', 'JJ'), ('(', '('), ('for', 'IN'), ('anonymization', 'NN'), (')', ')'), ('or', 'CC'), ('reversible', 'JJ'), ('(', '('), ('for', 'IN'), ('operational', 'JJ'), ('needs', 'NNS'), ('like', 'IN'), ('refunds', 'NNS'), (')', ')'), ('.', '.'), ('They', 'PRP'), ('may', 'MD'), ('also', 'RB'), ('be', 'VB'), ('format-preserving', 'JJ'), ('to', 'TO'), ('maintain', 'VB'), ('compatibility', 'NN'), ('with', 'IN'), ('existing', 'VBG'), ('systems', 'NNS'), ('.', '.')])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "1YUcwdspj0rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "ZGjikPHqj97L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "filtered_words"
      ],
      "metadata": {
        "id": "G2nKSkGxkHLH",
        "outputId": "14af6bbd-4eae-43b9-f30a-de19b134b82e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['theymayalsobeformat-preservtomaintaincompatwithexistsystem', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}